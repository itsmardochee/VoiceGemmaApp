import React, { useState, useEffect } from 'react';
import {
    SafeAreaView,
    StyleSheet,
    Text,
    View,
    TouchableOpacity,
    Alert,
    ScrollView,
    TextInput,
    Modal,
} from 'react-native';
import Voice from '@react-native-voice/voice';
import Tts from 'react-native-tts';
import { request, PERMISSIONS } from 'react-native-permissions';
import AsyncStorage from '@react-native-async-storage/async-storage';
import LlamaService from './services/LlamaService';
import { pick, keepLocalCopy, types } from '@react-native-documents/picker';

const translations = {
    fr: {
        title: 'ðŸŽ¤ Voice Gemma',
        subtitle: 'Assistant IA Local',
        youSaid: 'Vous avez dit:',
        pressToSpeak: 'Appuyez sur le micro pour parler...',
        gemmaResponse: 'RÃ©ponse Gemma:',
        gemmaThinking: 'Gemma rÃ©flÃ©chit...',
        speak: 'ðŸŽ¤ Parler',
        stop: 'ðŸ›‘ Stop',
        replay: 'ðŸ”Š Rejouer',
        stopReading: 'â¹ï¸ ArrÃªter',
        errorTitle: 'Erreur',
        voiceError: 'ProblÃ¨me avec la reconnaissance vocale',
        micPermissionTitle: 'Permission requise',
        micPermissionMessage: "L'accÃ¨s au microphone est nÃ©cessaire pour utiliser l'application",
        voiceStartError: 'Impossible de dÃ©marrer la reconnaissance vocale',
        llmError: "ProblÃ¨me lors du traitement par l'IA",
        llmInitError: "Erreur lors de l'initialisation du modÃ¨le IA",
        llmInitializing: 'Initialisation de Gemma...',
        llmDownloading: 'TÃ©lÃ©chargement du modÃ¨le...',
        llmResponse: (text) => `Vous avez dit: "${text}". Je suis Gemma 3, votre assistant IA local.`,
        ttsLanguage: 'fr-FR',
        voiceLanguage: 'fr-FR',
        modelManagement: 'Gestion du ModÃ¨le',
        selectModel: 'ðŸ“ SÃ©lectionner ModÃ¨le',
        downloadModel: 'ðŸ“¥ TÃ©lÃ©charger ModÃ¨le',
        modelUrl: 'URL du modÃ¨le:',
        download: 'TÃ©lÃ©charger',
        cancel: 'Annuler',
        currentModel: 'ModÃ¨le actuel:',
        noModel: 'Aucun modÃ¨le sÃ©lectionnÃ©',
        modelSelected: 'ModÃ¨le sÃ©lectionnÃ©',
        downloadProgress: 'TÃ©lÃ©chargement en cours...',
        downloadComplete: 'TÃ©lÃ©chargement terminÃ©',
        downloadError: 'Erreur de tÃ©lÃ©chargement',
        selectModelError: 'Erreur lors de la sÃ©lection du modÃ¨le',
        copyingModel: 'Copie du modÃ¨le en cours...',
        copyProgress: 'Copie:',
        modelCopied: 'ModÃ¨le copiÃ© avec succÃ¨s',
        copyError: 'Erreur lors de la copie du modÃ¨le',
    },
    en: {
        title: 'ðŸŽ¤ Voice Gemma',
        subtitle: 'Local AI Assistant',
        youSaid: 'You said:',
        pressToSpeak: 'Press the microphone to speak...',
        gemmaResponse: 'Gemma Response:',
        gemmaThinking: 'Gemma is thinking...',
        speak: 'ðŸŽ¤ Speak',
        stop: 'ðŸ›‘ Stop',
        replay: 'ðŸ”Š Replay',
        stopReading: 'â¹ï¸ Stop',
        errorTitle: 'Error',
        voiceError: 'Problem with voice recognition',
        micPermissionTitle: 'Permission Required',
        micPermissionMessage: 'Microphone access is required to use the application',
        voiceStartError: 'Unable to start voice recognition',
        llmError: 'Problem during AI processing',
        llmInitError: 'Error initializing AI model',
        llmInitializing: 'Initializing Gemma...',
        llmDownloading: 'Downloading model...',
        llmResponse: (text) => `You said: "${text}". I am Gemma 3, your local AI assistant.`,
        ttsLanguage: 'en-US',
        voiceLanguage: 'en-US',
        modelManagement: 'Model Management',
        selectModel: 'ðŸ“ Select Model',
        downloadModel: 'ðŸ“¥ Download Model',
        modelUrl: 'Model URL:',
        download: 'Download',
        cancel: 'Cancel',
        currentModel: 'Current model:',
        noModel: 'No model selected',
        modelSelected: 'Model selected',
        downloadProgress: 'Downloading...',
        downloadComplete: 'Download completed',
        downloadError: 'Download error',
        selectModelError: 'Error selecting model',
        copyingModel: 'Copying model...',
        copyProgress: 'Copy:',
        modelCopied: 'Model copied successfully',
        copyError: 'Error copying model',
    }
};

const App = () => {
    const [language, setLanguage] = useState('fr');
    const [isListening, setIsListening] = useState(false);
    const [recognizedText, setRecognizedText] = useState('');
    const [llmResponse, setLlmResponse] = useState('');
    const [isProcessing, setIsProcessing] = useState(false);
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isLlmReady, setIsLlmReady] = useState(false);
    const [llmStatus, setLlmStatus] = useState('');
    const [selectedModelPath, setSelectedModelPath] = useState('');
    const [showDownloadModal, setShowDownloadModal] = useState(false);
    const [downloadUrl, setDownloadUrl] = useState('https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-Q3_K_L.gguf');
    const [downloadProgress, setDownloadProgress] = useState(0);
    const [isDownloading, setIsDownloading] = useState(false);
    const [isCopying, setIsCopying] = useState(false);
    const [copyProgress, setCopyProgress] = useState(0);

    const STORAGE_KEYS = {
        SELECTED_MODEL_PATH: '@voice_gemma_selected_model_path',
        SELECTED_MODEL_NAME: '@voice_gemma_selected_model_name',
        IS_LLM_READY: '@voice_gemma_is_llm_ready',
    };

    const t = translations[language];

    const requestPermissions = async () => {
        try {
            console.log('ðŸ”’ Permissions: Demande de permission microphone');
            const result = await request(PERMISSIONS.ANDROID.RECORD_AUDIO);
            console.log('ðŸ”’ Permissions: RÃ©sultat permission microphone:', result);
            
            if (result !== 'granted') {
                Alert.alert(
                    t.micPermissionTitle,
                    t.micPermissionMessage
                );
            }
        } catch (error) {
            console.error('âŒ Permissions: Erreur lors de la demande de permission:', error);
        }
    };

    const toggleLanguage = () => {
        const newLanguage = language === 'fr' ? 'en' : 'fr';
        console.log(`ðŸŒ Language: Changement de langue: ${language} -> ${newLanguage}`);
        setLanguage(newLanguage);

        const newTtsLanguage = translations[newLanguage].ttsLanguage;
        Tts.setDefaultLanguage(newTtsLanguage);
        console.log(`ðŸ”Š TTS: Langue mise Ã  jour: ${newTtsLanguage}`);
    };

    useEffect(() => {
        console.log('ðŸš€ App: Initialisation des services Voice, TTS et LLM');

        // Configuration Voice
        Voice.onSpeechStart = e => {
            console.log("ðŸŽ¤ Voice: DÃ©but de l'Ã©coute", e);
            setIsListening(true);
        };

        Voice.onSpeechEnd = e => {
            console.log("ðŸŽ¤ Voice: Fin de l'Ã©coute", e);
            setIsListening(false);
        };

        Voice.onSpeechResults = e => {
            const text = e.value[0];
            console.log('ðŸŽ¤ Voice: RÃ©sultats de reconnaissance:', {
                allResults: e.value,
                selectedText: text,
            });
            setRecognizedText(text);
            processWithLLM(text);
        };

        Voice.onSpeechError = e => {
            console.error('âŒ Voice: Erreur de reconnaissance:', e);
            setIsListening(false);
            Alert.alert(t.errorTitle, t.voiceError);
        };

        Voice.onSpeechPartialResults = e => {
            console.log('ðŸŽ¤ Voice: RÃ©sultats partiels:', e.value);
        };

        Voice.onSpeechVolumeChanged = e => {
            console.log('ðŸ”Š Voice: Volume changÃ©:', e.value);
        };

        // Configuration TTS
        console.log('ðŸ”Š TTS: Configuration de la synthÃ¨se vocale');
        Tts.setDefaultLanguage(t.ttsLanguage);
        Tts.setDefaultRate(0.5);

        // Ã‰vÃ©nements TTS
        Tts.addEventListener('tts-start', event => {
            console.log('ðŸ”Š TTS: DÃ©but de la synthÃ¨se', event);
            setIsSpeaking(true);
        });

        Tts.addEventListener('tts-finish', event => {
            console.log('ðŸ”Š TTS: Fin de la synthÃ¨se', event);
            setIsSpeaking(false);
        });

        Tts.addEventListener('tts-cancel', event => {
            console.log('ðŸ”Š TTS: SynthÃ¨se annulÃ©e', event);
            setIsSpeaking(false);
        });

        // VÃ©rifier s'il y a un modÃ¨le sauvegardÃ©
        loadSavedModel();

        requestPermissions();

        return () => {
            console.log('ðŸ§¹ App: Nettoyage des services');
            Voice.destroy().then(Voice.removeAllListeners);
            Tts.removeAllListeners('tts-start');
            Tts.removeAllListeners('tts-finish');
            Tts.removeAllListeners('tts-cancel');
            LlamaService.cleanup();
        };
    }, [language]);

    // Fonction pour charger le modÃ¨le sauvegardÃ©
    const loadSavedModel = async () => {
        try {
            const savedModelPath = await AsyncStorage.getItem(STORAGE_KEYS.SELECTED_MODEL_PATH);
            const savedModelName = await AsyncStorage.getItem(STORAGE_KEYS.SELECTED_MODEL_NAME);
            
            if (savedModelPath) {
                console.log('ðŸ“ App: ModÃ¨le sauvegardÃ© trouvÃ©:', savedModelPath);
                
                // VÃ©rifier si le fichier existe encore
                const LlamaServiceFS = require('./services/LlamaService').default;
                const exists = await LlamaServiceFS.checkFileExists(savedModelPath);
                
                if (exists) {
                    setSelectedModelPath(savedModelPath);
                    console.log('âœ… App: ModÃ¨le restaurÃ©:', savedModelName);
                    
                    // Essayer d'initialiser automatiquement
                    try {
                        setLlmStatus(t.llmInitializing);
                        await LlamaService.initialize(savedModelPath);
                        setIsLlmReady(true);
                        setLlmStatus('');
                        console.log('âœ… App: LLM rÃ©initialisÃ© automatiquement');
                    } catch (error) {
                        console.error('âŒ App: Erreur lors de la rÃ©initialisation automatique:', error);
                        setLlmStatus(t.noModel);
                        setIsLlmReady(false);
                    }
                } else {
                    console.warn('âš ï¸ App: Fichier modÃ¨le sauvegardÃ© introuvable, nettoyage...');
                    await AsyncStorage.multiRemove([
                        STORAGE_KEYS.SELECTED_MODEL_PATH,
                        STORAGE_KEYS.SELECTED_MODEL_NAME,
                        STORAGE_KEYS.IS_LLM_READY
                    ]);
                    setLlmStatus(t.noModel);
                    setIsLlmReady(false);
                }
            } else {
                console.log('âš ï¸ App: Aucun modÃ¨le sauvegardÃ© trouvÃ©');
                setLlmStatus(t.noModel);
                setIsLlmReady(false);
            }
        } catch (error) {
            console.error('âŒ App: Erreur lors du chargement du modÃ¨le sauvegardÃ©:', error);
            setLlmStatus(t.noModel);
            setIsLlmReady(false);
        }
    };

    // Fonction pour sauvegarder le modÃ¨le
    const saveModelInfo = async (modelPath: string, modelName: string) => {
        try {
            await AsyncStorage.multiSet([
                [STORAGE_KEYS.SELECTED_MODEL_PATH, modelPath],
                [STORAGE_KEYS.SELECTED_MODEL_NAME, modelName],
                [STORAGE_KEYS.IS_LLM_READY, 'true']
            ]);
            console.log('ðŸ’¾ App: Informations du modÃ¨le sauvegardÃ©es');
        } catch (error) {
            console.error('âŒ App: Erreur lors de la sauvegarde:', error);
        }
    };

    const startListening = async () => {
        console.log('â–¶ï¸ User Action: Bouton "Commencer l\'Ã©coute" pressÃ©');
        try {
            console.log(`ðŸŽ¤ Voice: DÃ©marrage de la reconnaissance vocale (${t.voiceLanguage})`);
            await Voice.start(t.voiceLanguage);
            console.log('âœ… Voice: Service de reconnaissance dÃ©marrÃ© avec succÃ¨s');
        } catch (error) {
            console.error('âŒ Voice: Erreur lors du dÃ©marrage:', error);
            Alert.alert(t.errorTitle, t.voiceStartError);
        }
    };

    const stopListening = async () => {
        console.log('â¹ï¸ User Action: Bouton "ArrÃªter l\'Ã©coute" pressÃ©');
        try {
            console.log('ðŸŽ¤ Voice: ArrÃªt de la reconnaissance vocale');
            await Voice.stop();
            console.log('âœ… Voice: Service de reconnaissance arrÃªtÃ© avec succÃ¨s');
        } catch (error) {
            console.error("âŒ Voice: Erreur lors de l'arrÃªt:", error);
        }
    };

    const initializeLLM = async () => {
        try {
            setLlmStatus(t.llmInitializing);
            console.log('ðŸ¤– LLM: DÃ©but de l\'initialisation');
            console.log('ðŸ¤– LLM: Chemin du modÃ¨le disponible:', selectedModelPath);
            
            if (!selectedModelPath) {
                console.warn('âš ï¸ LLM: Aucun modÃ¨le sÃ©lectionnÃ©, tentative avec modÃ¨le par dÃ©faut...');
                // Essayer d'initialiser avec le modÃ¨le par dÃ©faut
                await LlamaService.initialize();
                setIsLlmReady(true);
                setLlmStatus('');
                console.log('âœ… LLM: InitialisÃ© avec modÃ¨le par dÃ©faut');
                return;
            }
            
            await LlamaService.initialize(selectedModelPath);
            
            setIsLlmReady(true);
            setLlmStatus('');
            console.log('âœ… LLM: PrÃªt Ã  Ãªtre utilisÃ© avec:', selectedModelPath);
        } catch (error) {
            console.error('âŒ LLM: Erreur d\'initialisation:', error);
            setLlmStatus(t.llmInitError);
            Alert.alert(t.errorTitle, t.llmInitError);
        }
    };

    const selectModelFile = async () => {
        try {
            const [result] = await pick({
                type: [types.allFiles],
            });

            if (result) {
                console.log('ðŸ“ Model: Fichier sÃ©lectionnÃ©:', result.name, 'Taille:', result.size);
                console.log('ðŸ“ Model: URI original:', result.uri);
                
                // VÃ©rifier si ce modÃ¨le existe dÃ©jÃ 
                const targetFileName = result.name ?? 'selected-model.gguf';
                const existingModelPath = await LlamaService.findExistingModel(targetFileName);
                
                if (existingModelPath) {
                    console.log('â™»ï¸ Model: ModÃ¨le existant trouvÃ©, rÃ©utilisation:', existingModelPath);
                    
                    setSelectedModelPath(existingModelPath);
                    setIsLlmReady(false);
                    setLlmResponse('');
                    
                    try {
                        setLlmStatus(t.llmInitializing);
                        await LlamaService.initialize(existingModelPath);
                        
                        setIsLlmReady(true);
                        setLlmStatus('');
                        
                        // Sauvegarder les informations
                        await saveModelInfo(existingModelPath, result.name);
                        
                        Alert.alert(t.modelSelected, `${result.name}\n\nModÃ¨le rÃ©utilisÃ© (pas de copie nÃ©cessaire)\n\nGemma est prÃªt !`);
                        console.log('âœ… Model: LLM initialisÃ© avec modÃ¨le existant');
                    } catch (initError) {
                        console.error('âŒ Model: Erreur d\'initialisation:', initError);
                        setLlmStatus(t.llmInitError);
                        Alert.alert(t.errorTitle, `Erreur d'initialisation: ${initError.message}`);
                    }
                    return;
                }
                
                // Sinon, procÃ©der Ã  la copie comme avant
                setIsCopying(true);
                setCopyProgress(0);
                setLlmStatus(`${t.copyingModel} 0%`);
                
                const progressInterval = setInterval(() => {
                    setCopyProgress(prev => {
                        const newProgress = Math.min(prev + 0.02, 0.95);
                        setLlmStatus(`${t.copyProgress} ${Math.round(newProgress * 100)}%`);
                        return newProgress;
                    });
                }, 100);

                try {
                    const localCopyResult = await keepLocalCopy({
                        files: [
                            {
                                uri: result.uri,
                                fileName: result.name ?? 'selected-model.gguf',
                            },
                        ],
                        destination: 'documentDirectory',
                    });

                    console.log('ðŸ“ Model: RÃ©sultat de la copie:', localCopyResult);
                    
                    clearInterval(progressInterval);
                    setCopyProgress(1);
                    setLlmStatus(t.modelCopied);

                    let modelPath;
                    if (Array.isArray(localCopyResult) && localCopyResult.length > 0) {
                        const [localCopy] = localCopyResult;
                        modelPath = localCopy.localUri || localCopy.uri || localCopy.fileCopyUri || localCopy.path;
                    } else {
                        modelPath = localCopyResult.localUri || localCopyResult.uri || localCopyResult.fileCopyUri || localCopyResult.path;
                    }
                    
                    if (!modelPath) {
                        throw new Error('Impossible de dÃ©terminer le chemin du fichier copiÃ©');
                    }

                    setSelectedModelPath(modelPath);
                    setIsLlmReady(false);
                    setLlmResponse('');
                    
                    setTimeout(async () => {
                        setIsCopying(false);
                        console.log('ðŸš€ Model: DÃ©marrage automatique de l\'initialisation du LLM avec:', modelPath);
                        
                        try {
                            setLlmStatus(t.llmInitializing);
                            await LlamaService.initialize(modelPath);
                            
                            setIsLlmReady(true);
                            setLlmStatus('');
                            
                            // Sauvegarder les informations
                            await saveModelInfo(modelPath, result.name);
                            
                            Alert.alert(t.modelSelected, `${result.name}\n${t.modelCopied}\n\nGemma est prÃªt Ã  Ãªtre utilisÃ© !`);
                            console.log('âœ… Model: LLM initialisÃ© et prÃªt');
                        } catch (initError) {
                            console.error('âŒ Model: Erreur d\'initialisation automatique:', initError);
                            setLlmStatus(t.llmInitError);
                            Alert.alert(t.errorTitle, `${t.modelCopied}\n\nMais erreur d'initialisation: ${initError.message}`);
                        }
                    }, 1000);
                    
                } catch (copyError) {
                    clearInterval(progressInterval);
                    throw copyError;
                }
            }
        } catch (error) {
            setIsCopying(false);
            setCopyProgress(0);
            setLlmStatus('');
            
            if (error.message && error.message.includes('cancelled')) {
                console.log('ðŸ“ Model: SÃ©lection annulÃ©e par l\'utilisateur');
            } else {
                console.error('âŒ Model: Erreur de sÃ©lection/copie:', error);
                Alert.alert(t.errorTitle, `${t.copyError}: ${error.message}`);
            }
        }
    };

    const downloadModel = async () => {
        if (!downloadUrl.trim()) {
            Alert.alert(t.errorTitle, 'URL requise');
            return;
        }

        // VÃ©rifier si le modÃ¨le existe dÃ©jÃ 
        const fileName = downloadUrl.split('/').pop() || 'downloaded-model.gguf';
        const existingModelPath = await LlamaService.findExistingModel(fileName);
        
        if (existingModelPath) {
            console.log('â™»ï¸ Download: ModÃ¨le dÃ©jÃ  tÃ©lÃ©chargÃ©, rÃ©utilisation:', existingModelPath);
            
            setSelectedModelPath(existingModelPath);
            setShowDownloadModal(false);
            
            try {
                setLlmStatus(t.llmInitializing);
                await LlamaService.initialize(existingModelPath);
                
                setIsLlmReady(true);
                setLlmStatus('');
                
                // Sauvegarder les informations
                await saveModelInfo(existingModelPath, fileName);
                
                Alert.alert(t.modelSelected, `${fileName}\n\nModÃ¨le rÃ©utilisÃ© (pas de tÃ©lÃ©chargement nÃ©cessaire)\n\nGemma est prÃªt !`);
                console.log('âœ… Download: LLM initialisÃ© avec modÃ¨le existant');
            } catch (initError) {
                console.error('âŒ Download: Erreur d\'initialisation:', initError);
                setLlmStatus(t.llmInitError);
                Alert.alert(t.errorTitle, `Erreur d'initialisation: ${initError.message}`);
            }
            return;
        }

        // Sinon, procÃ©der au tÃ©lÃ©chargement
        setIsDownloading(true);
        setDownloadProgress(0);
        setShowDownloadModal(false);

        try {
            const modelPath = await LlamaService.downloadModel(
                downloadUrl,
                (progress) => {
                    setDownloadProgress(progress);
                    setLlmStatus(`${t.downloadProgress} ${Math.round(progress * 100)}%`);
                }
            );

            setSelectedModelPath(modelPath);
            setIsDownloading(false);
            
            console.log('ðŸš€ Download: DÃ©marrage automatique de l\'initialisation du LLM');
            try {
                setLlmStatus(t.llmInitializing);
                await LlamaService.initialize(modelPath);
                
                setIsLlmReady(true);
                setLlmStatus('');
                
                // Sauvegarder les informations
                await saveModelInfo(modelPath, fileName);
                
                Alert.alert(t.downloadComplete, 'Gemma est prÃªt Ã  Ãªtre utilisÃ© !');
                console.log('âœ… Download: LLM initialisÃ© et prÃªt');
            } catch (initError) {
                console.error('âŒ Download: Erreur d\'initialisation automatique:', initError);
                setLlmStatus(t.llmInitError);
                Alert.alert(t.errorTitle, `${t.downloadComplete}\n\nMais erreur d'initialisation: ${initError.message}`);
            }
            
        } catch (error) {
            setIsDownloading(false);
            setLlmStatus('');
            console.error('âŒ Model: Erreur de tÃ©lÃ©chargement:', error);
            Alert.alert(t.errorTitle, t.downloadError);
        }
    };

    const processWithLLM = async text => {
        console.log('ðŸ¤– LLM: DÃ©but du traitement du texte:', text);
        console.log('ðŸ¤– LLM: Ã‰tat actuel - isLlmReady:', isLlmReady, 'selectedModelPath:', selectedModelPath);
        
        setIsProcessing(true);
        setLlmResponse(''); // Vider la rÃ©ponse prÃ©cÃ©dente

        try {
            // VÃ©rifier d'abord si le contexte LLM existe
            const isContextReady = LlamaService.isReady();
            console.log('ðŸ” LLM: VÃ©rification du contexte:', isContextReady);

            if (!isContextReady) {
                console.warn('âš ï¸ LLM: Contexte non disponible, tentative d\'initialisation...');
                
                if (selectedModelPath) {
                    console.log('ðŸ”„ LLM: RÃ©initialisation avec modÃ¨le sÃ©lectionnÃ©:', selectedModelPath);
                    await LlamaService.initialize(selectedModelPath);
                } else {
                    console.log('ðŸ”„ LLM: Tentative d\'initialisation avec modÃ¨le par dÃ©faut...');
                    await LlamaService.initialize();
                }
                
                setIsLlmReady(true);
                console.log('âœ… LLM: Contexte rÃ©initialisÃ© avec succÃ¨s');
            } else if (!isLlmReady) {
                // Le contexte existe mais l'Ã©tat n'est pas Ã  jour
                setIsLlmReady(true);
                console.log('âœ… LLM: Ã‰tat mis Ã  jour - contexte dÃ©jÃ  prÃªt');
            }

            const messages = [
                {
                    role: 'system' as const,
                    content: language === 'fr' 
                        ? 'Tu es Gemma, un assistant IA concis. RÃ©ponds en franÃ§ais en 1-2 phrases maximum.'
                        : 'You are Gemma, a concise AI assistant. Respond in English with 1-2 sentences maximum.'
                },
                {
                    role: 'user' as const,
                    content: text
                }
            ];

            // Ajouter un callback pour afficher la gÃ©nÃ©ration en temps rÃ©el
            let partialResponse = '';
            const response = await LlamaService.completion(messages, (tokenData) => {
                if (tokenData.token) {
                    partialResponse += tokenData.token;
                    setLlmResponse(partialResponse);
                }
            });
            
            console.log('ðŸ¤– LLM: RÃ©ponse gÃ©nÃ©rÃ©e:', response);
            setLlmResponse(response);
            speakResponse(response);
            setIsProcessing(false);

            console.log('âœ… LLM: Traitement terminÃ© avec succÃ¨s');
        } catch (error) {
            console.error('âŒ LLM: Erreur lors du traitement:', error);
            setIsProcessing(false);
            
            // Fallback response avec message d'erreur spÃ©cifique
            const fallbackResponse = language === 'fr'
                ? `DÃ©solÃ©, erreur: ${error.message}`
                : `Sorry, error: ${error.message}`;
            
            setLlmResponse(fallbackResponse);
            speakResponse(fallbackResponse);
            Alert.alert(t.errorTitle, error.message);
        }
    };

    const speakResponse = text => {
        console.log(
            'ðŸ”Š TTS: DÃ©but de la synthÃ¨se vocale pour:',
            text.substring(0, 50) + '...',
        );
        try {
            Tts.speak(text);
            console.log('âœ… TTS: Commande de synthÃ¨se envoyÃ©e');
        } catch (error) {
            console.error('âŒ TTS: Erreur lors de la synthÃ¨se:', error);
        }
    };

    const stopSpeaking = () => {
        console.log('â¹ï¸ User Action: Bouton "ArrÃªter lecture" pressÃ©');
        try {
            Tts.stop();
            console.log('âœ… TTS: Lecture arrÃªtÃ©e');
        } catch (error) {
            console.error('âŒ TTS: Erreur lors de l\'arrÃªt:', error);
        }
    };

    const handleReplayPress = () => {
        if (isSpeaking) {
            console.log('ðŸ”„ User Action: Bouton "ArrÃªter" pressÃ©');
            stopSpeaking();
        } else {
            console.log('ðŸ”„ User Action: Bouton "Rejouer" pressÃ©');
            speakResponse(llmResponse);
        }
    };

    return (
        <SafeAreaView style={styles.container}>
            <View style={styles.header}>
                <View style={styles.headerContent}>
                    <View style={styles.titleContainer}>
                        <Text style={styles.title}>{t.title}</Text>
                        <Text style={styles.subtitle}>{t.subtitle}</Text>
                    </View>
                    <TouchableOpacity
                        style={styles.languageButton}
                        onPress={toggleLanguage}
                    >
                        <Text style={styles.flagText}>
                            {language === 'fr' ? 'ðŸ‡«ðŸ‡·' : 'ðŸ‡ºðŸ‡¸'}
                        </Text>
                    </TouchableOpacity>
                </View>
            </View>

            <ScrollView style={styles.content}>
                <View style={styles.section}>
                    <Text style={styles.sectionTitle}>{t.modelManagement}</Text>
                    <Text style={styles.modelInfo}>
                        {t.currentModel} {selectedModelPath ? 
                            selectedModelPath.split('/').pop() : t.noModel}
                    </Text>
                    
                    {/* Barre de progression pour la copie */}
                    {isCopying && (
                        <View style={styles.progressContainer}>
                            <View style={styles.progressBar}>
                                <View 
                                    style={[styles.progressFill, { width: `${copyProgress * 100}%` }]}
                                />
                            </View>
                            <Text style={styles.progressText}>
                                {Math.round(copyProgress * 100)}%
                            </Text>
                        </View>
                    )}
                    
                    <View style={styles.modelButtons}>
                        <TouchableOpacity
                            style={[styles.modelButton, (isDownloading || isCopying) && styles.modelButtonDisabled]}
                            onPress={selectModelFile}
                            disabled={isDownloading || isCopying}>
                            <Text style={styles.modelButtonText}>{t.selectModel}</Text>
                        </TouchableOpacity>
                        
                        <TouchableOpacity
                            style={[styles.modelButton, (isDownloading || isCopying) && styles.modelButtonDisabled]}
                            onPress={() => setShowDownloadModal(true)}
                            disabled={isDownloading || isCopying}>
                            <Text style={styles.modelButtonText}>{t.downloadModel}</Text>
                        </TouchableOpacity>
                    </View>

                    {/* Le bouton d'initialisation manuelle n'est plus nÃ©cessaire 
                        car l'initialisation se fait automatiquement */}
                    {selectedModelPath && !isLlmReady && !isCopying && !isDownloading && (
                        <TouchableOpacity
                            style={styles.initButton}
                            onPress={initializeLLM}
                            disabled={false}>
                            <Text style={styles.initButtonText}>ðŸ”„ RÃ©initialiser Gemma</Text>
                        </TouchableOpacity>
                    )}
                </View>

                <View style={styles.section}>
                    <Text style={styles.sectionTitle}>{t.youSaid}</Text>
                    <Text style={styles.recognizedText}>
                        {recognizedText || t.pressToSpeak}
                    </Text>
                </View>

                <View style={styles.section}>
                    <Text style={styles.sectionTitle}>{t.gemmaResponse}</Text>
                    <Text style={styles.responseText}>
                        {!isLlmReady && llmStatus ? llmStatus :
                         isProcessing ? t.gemmaThinking : 
                         llmResponse}
                    </Text>
                </View>
            </ScrollView>

            <View style={styles.controls}>
                <TouchableOpacity
                    style={[styles.micButton, isListening && styles.micButtonActive]}
                    onPress={isListening ? stopListening : startListening}
                    disabled={isProcessing || !isLlmReady || isCopying}>
                    <Text style={styles.micButtonText}>
                        {isListening ? t.stop : t.speak}
                    </Text>
                </TouchableOpacity>

                {llmResponse ? (
                    <TouchableOpacity
                        style={[styles.replayButton, isSpeaking && styles.stopButton]}
                        onPress={handleReplayPress}>
                        <Text style={styles.replayButtonText}>
                            {isSpeaking ? t.stopReading : t.replay}
                        </Text>
                    </TouchableOpacity>
                ) : null}
            </View>

            <Modal
                visible={showDownloadModal}
                transparent={true}
                animationType="slide">
                <View style={styles.modalOverlay}>
                    <View style={styles.modalContent}>
                        <Text style={styles.modalTitle}>{t.downloadModel}</Text>
                        
                        <Text style={styles.inputLabel}>{t.modelUrl}</Text>
                        <TextInput
                            style={styles.urlInput}
                            value={downloadUrl}
                            onChangeText={setDownloadUrl}
                            placeholder="https://..."
                            placeholderTextColor="#666"
                            multiline
                        />
                        
                        <View style={styles.modalButtons}>
                            <TouchableOpacity
                                style={[styles.modalButton, styles.cancelButton]}
                                onPress={() => setShowDownloadModal(false)}>
                                <Text style={styles.modalButtonText}>{t.cancel}</Text>
                            </TouchableOpacity>
                            
                            <TouchableOpacity
                                style={[styles.modalButton, styles.downloadButton]}
                                onPress={downloadModel}>
                                <Text style={styles.modalButtonText}>{t.download}</Text>
                            </TouchableOpacity>
                        </View>
                    </View>
                </View>
            </Modal>
        </SafeAreaView>
    );
};

const styles = StyleSheet.create({
    container: {
        flex: 1,
        paddingTop: 20,
        backgroundColor: '#1a1a1a',
    },
    header: {
        padding: 20,
        borderBottomWidth: 1,
        borderBottomColor: '#333',
    },
    headerContent: {
        flexDirection: 'row',
        justifyContent: 'space-between',
        alignItems: 'center',
    },
    titleContainer: {
        flex: 1,
        alignItems: 'center',
    },
    title: {
        fontSize: 28,
        fontWeight: 'bold',
        color: '#fff',
    },
    subtitle: {
        fontSize: 16,
        color: '#888',
        marginTop: 5,
    },
    languageButton: {
        padding: 8,
        borderRadius: 8,
        backgroundColor: '#333',
    },
    flagText: {
        fontSize: 24,
    },
    content: {
        flex: 1,
        padding: 20,
    },
    section: {
        marginBottom: 30,
        padding: 15,
        backgroundColor: '#2a2a2a',
        borderRadius: 10,
    },
    sectionTitle: {
        fontSize: 16,
        fontWeight: 'bold',
        color: '#4CAF50',
        marginBottom: 10,
    },
    recognizedText: {
        fontSize: 18,
        color: '#fff',
        lineHeight: 24,
    },
    responseText: {
        fontSize: 16,
        color: '#e0e0e0',
        lineHeight: 22,
    },
    controls: {
        padding: 20,
        alignItems: 'center',
    },
    micButton: {
        backgroundColor: '#4CAF50',
        paddingHorizontal: 30,
        paddingVertical: 15,
        borderRadius: 25,
        marginBottom: 10,
    },
    micButtonActive: {
        backgroundColor: '#f44336',
    },
    micButtonText: {
        color: '#fff',
        fontSize: 18,
        fontWeight: 'bold',
    },
    replayButton: {
        backgroundColor: '#2196F3',
        paddingHorizontal: 20,
        paddingVertical: 10,
        borderRadius: 20,
    },
    stopButton: {
        backgroundColor: '#FF9800',
    },
    replayButtonText: {
        color: '#fff',
        fontSize: 14,
    },
    modelInfo: {
        fontSize: 14,
        color: '#ccc',
        marginBottom: 15,
    },
    modelButtons: {
        flexDirection: 'row',
        justifyContent: 'space-between',
        marginBottom: 10,
    },
    modelButton: {
        backgroundColor: '#4CAF50',
        paddingHorizontal: 15,
        paddingVertical: 10,
        borderRadius: 8,
        flex: 0.48,
    },
    modelButtonText: {
        color: '#fff',
        fontSize: 12,
        textAlign: 'center',
        fontWeight: 'bold',
    },
    initButton: {
        backgroundColor: '#FF9800',
        paddingHorizontal: 20,
        paddingVertical: 12,
        borderRadius: 8,
        alignSelf: 'center',
        marginTop: 10,
    },
    initButtonText: {
        color: '#fff',
        fontSize: 14,
        fontWeight: 'bold',
    },
    modalOverlay: {
        flex: 1,
        backgroundColor: 'rgba(0,0,0,0.8)',
        justifyContent: 'center',
        alignItems: 'center',
    },
    modalContent: {
        backgroundColor: '#2a2a2a',
        borderRadius: 15,
        padding: 20,
        width: '90%',
        maxWidth: 400,
    },
    modalTitle: {
        fontSize: 18,
        fontWeight: 'bold',
        color: '#fff',
        textAlign: 'center',
        marginBottom: 20,
    },
    inputLabel: {
        fontSize: 14,
        color: '#4CAF50',
        marginBottom: 8,
    },
    urlInput: {
        backgroundColor: '#1a1a1a',
        color: '#fff',
        borderRadius: 8,
        padding: 12,
        marginBottom: 20,
        minHeight: 60,
        textAlignVertical: 'top',
    },
    modalButtons: {
        flexDirection: 'row',
        justifyContent: 'space-between',
    },
    modalButton: {
        paddingHorizontal: 20,
        paddingVertical: 12,
        borderRadius: 8,
        flex: 0.45,
    },
    cancelButton: {
        backgroundColor: '#666',
    },
    downloadButton: {
        backgroundColor: '#2196F3',
    },
    modalButtonText: {
        color: '#fff',
        fontSize: 14,
        textAlign: 'center',
        fontWeight: 'bold',
    },
    progressContainer: {
        marginVertical: 15,
        alignItems: 'center',
    },
    progressBar: {
        width: '100%',
        height: 8,
        backgroundColor: '#444',
        borderRadius: 4,
        overflow: 'hidden',
        marginBottom: 8,
    },
    progressFill: {
        height: '100%',
        backgroundColor: '#4CAF50',
        borderRadius: 4,
    },
    progressText: {
        color: '#4CAF50',
        fontSize: 12,
        fontWeight: 'bold',
    },
    modelButtonDisabled: {
        backgroundColor: '#666',
        opacity: 0.6,
    },
});

export default App;
